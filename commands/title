#!/usr/bin/env python3

# http://inamidst.com/saxo/
# Created by Sean B. Palmer

import html.entities
import re

import saxo

regex_link = re.compile(r"^(http[s]?://[^<> \"\x01]+)[,.]?$")
regex_title = re.compile(r"(?ims)<title[^>]*>(.*?)</title>")
regex_script = re.compile(r"(?ims)<script(.*?)</script>")
regex_tag = re.compile(r"<[^>]+>")
regex_entity = re.compile(r"&([^;\s]+);")

def longest(input, sep):
    longest = 0
    result = ""
    for part in input.split(sep):
        part = part.strip()
        if len(part) > longest:
           longest = len(part)
           result = part
    return result

blacklist = (
    "swhack.com",
    "translate.google.com",
    "wikia.com",
    "wikipedia.org"
)

def decode_entities(hypertext):
    def entity(match):
        name = match.group(1).lower()

        if name.startswith("#x"):
            return chr(int(name[2:], 16))
        elif name.startswith("#"):
            return chr(int(name[1:]))
        elif name in html.entities.name2codepoint:
            return chr(html.entities.name2codepoint[name])
        return "[" + name + "]"

    return regex_entity.sub(entity, hypertext)

@saxo.pipe
def title(url):
    if not url:
        url = saxo.env("url")
    if not url:
        return "Sorry, no link found to title"
    if " " in url:
        return "Sorry, links cannot contain spaces"

    if not url.startswith("http"):
        url = "http://" + url

    if "#" in url:
        url = url.split("#", 1)[0]

    if "//en.wikipedia.org/" in url:
        article = url.split("/").pop()
        return saxo.call("wik", article)

    for blacklisted in blacklist:
        if blacklisted in url:
            return "Sorry, domain is blacklisted"

    if "nytimes.com" in url:
        return url.rsplit(".html", 1)[0].rsplit("/").pop()

    if (url.startswith("https://youtube.com/watch?v=") or
        url.startswith("https://www.youtube.com/watch?v=")):
        url = url.replace("/watch?v=", "/embed/", 1)

    page = saxo.request(url, limit=262144, follow=True)
    if "html" not in page:
        return "Sorry, page isn't HTML"
    text = regex_script.sub("", page["html"])
    search = regex_title.search(text)
    if search:
        title = search.group(1)
        title = regex_tag.sub("", title)
        title = decode_entities(title)
        title = title.replace("\r", "")
        title = title.replace("\n", "")

        # title = longest(title, " : ")
        # title = longest(title, " | ")
        # title = longest(title, "| ")
        # title = longest(title, " â€” ")
        # if "youtube.com" not in url:
        #     title = longest(title, " - ")
        # elif title.endswith(" - YouTube"):
        #     title = title[:-10]
        title = title.replace('"', "'")
        return title.strip()
    return "No title found"
